{
 "metadata": {
  "name": "",
  "signature": "sha256:9e5a8adccf003d4920ed0cd8860c66cd5de8923a8c438b090bb6dc1b19dd0d01"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "PIL :("
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function, division\n",
      "import sys, six\n",
      "sys.path.append('..'); import pathcustomize, about\n",
      "about.about()\n",
      "\n",
      "import numpy as np\n",
      "#import matplotlib\n",
      "#matplotlib.use('Agg')\n",
      "import matplotlib.pyplot as plt\n",
      "from PIL import Image\n",
      "\n",
      "from waldo import wio\n",
      "from waldo import collider\n",
      "from waldo.collider.viz.tools import get_contour, patch_contours, Box"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ex_id = '20130614_120518'\n",
      "#ex_id = '20130318_131111'\n",
      "#ex_id = '20130414_140704'\n",
      "ex_id = '20130702_135704' # many pics\n",
      "#ex_id = '20130702_135652' # many pics\n",
      "\n",
      "experiment = wio.Experiment(experiment_id=ex_id)\n",
      "graph = experiment.graph.copy()\n",
      "collider.remove_nodes_outside_roi(graph, experiment)\n",
      "len(graph)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "frame = 1000\n",
      "frame_img, img_time = experiment.image_files.nearest(frame=frame)\n",
      "bids = experiment.blobs_in_frame(frame)\n",
      "\n",
      "blob = experiment[bids[2]]\n",
      "blob.df.decode_contour()\n",
      "frame_data = blob.df[blob.df.frame == frame]\n",
      "centroid = frame_data['centroid'].values[0]\n",
      "contour = frame_data['contour'].values[0] # extract list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pillowed(img_file):\n",
      "    \"\"\"\n",
      "    PIL load...haha.\n",
      "    \n",
      "    Transposes the image into the correct coordinate system\n",
      "    \"\"\"\n",
      "    img = Image.open(img_file)\n",
      "    img = img.transpose(Image.FLIP_LEFT_RIGHT).transpose(Image.ROTATE_90) \n",
      "    return img\n",
      "\n",
      "def pil_crop(img, box):\n",
      "    \"\"\"\n",
      "    Crops the given PIL image approximately around the given box (cut \n",
      "    at integers to align with pixels). Returns another PIL image and \n",
      "    extent box\n",
      "    \"\"\"\n",
      "    extents = Box([int(x) for x in box])\n",
      "    retimg = img.crop(extents.PIL)\n",
      "    extents.center = (c - 0.5 for c in extents.center)    \n",
      "    return retimg, extents"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#sqsize = 40\n",
      "#zoombox = Box(center=centroid, size=(sqsize, sqsize))\n",
      "#zoombox.PIL"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f, ax = plt.subplots()\n",
      "\n",
      "f.set_size_inches((10, 10))\n",
      "\n",
      "box = Box.fit(contour)\n",
      "box.grow(5)\n",
      "\n",
      "img = pillowed(frame_img.open('rb'))\n",
      "img, extents = pil_crop(img, box)\n",
      "imarr = np.asarray(img)\n",
      "\n",
      "ax.imshow(imarr, cmap=plt.cm.YlOrBr, extent=extents.vflip, interpolation='nearest')\n",
      "\n",
      "ax.plot(*zip(*contour))\n",
      "\n",
      "limits = Box(extents)\n",
      "limits.grow(3)\n",
      "\n",
      "ax.set_xlim(limits.x)\n",
      "ax.set_ylim(limits.y)\n",
      "plt.show()\n",
      "print(extents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "OK, now how about some gaps."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from PIL import ImageOps, ImageChops\n",
      "\n",
      "def adjust_image(im):\n",
      "    # - reduce 16-bit greyscale to 8-bit\n",
      "    im = im.point([int(x/256) for x in range(2**16)], 'L')\n",
      "    im = ImageOps.autocontrast(im, cutoff=0)\n",
      "    return im\n",
      "\n",
      "def merge_stack(images):\n",
      "    '''\n",
      "    Merges a series of *images* using ***math***.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    images : iterable of :py:class:`PIL.Image.Image`\n",
      "        Image stack\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    :py:class:`PIL.Image.Image`\n",
      "        Merged image\n",
      "    '''\n",
      "    # Guards\n",
      "    if not images:\n",
      "        raise ValueError('No images provided')\n",
      "    elif len(images) == 1:\n",
      "        return images[0]\n",
      "\n",
      "    # Convert Image\n",
      "    # - compress first\n",
      "    #print images[0].histogram()\n",
      "    #lut = equalize(images[0].histogram())\n",
      "    \n",
      "    # stack up, keeping darkest pixels\n",
      "    composite = ImageChops.darker(images[0], images[1])\n",
      "    for im in images[2:]:\n",
      "        composite = ImageChops.darker(composite, im)\n",
      "    return composite"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "\n",
      "gaps = []\n",
      "gaps.extend((22, x) for x in [64, 66, 91, 92, 94, 96, 97, 98, 111, 120])\n",
      "gaps.extend((70, x) for x in [91, 92, 94, 96, 97, 98, 111, 120, 126, 128, 153])\n",
      "gaps.extend((11, x) for x in [96, 120, 126, 128, 153, 167, 175, 184])\n",
      "\n",
      "for lost, found in gaps[:2]:\n",
      "    boxes = []\n",
      "    blobs = []\n",
      "    shapes = []\n",
      "    times = []\n",
      "    centroids = []\n",
      "    \n",
      "    for bid, end in zip([lost, found], ['last', 'first']):\n",
      "        blob = experiment[bid]\n",
      "        blob.df.decode_contour()\n",
      "        blob_shape = get_contour(blob, end)\n",
      "        blob_box = Box.fit(blob_shape)\n",
      "        idx = -1 if end == 'last' else 0\n",
      "        time = blob.df['time'].iloc[idx]\n",
      "        centroid = blob.df['centroid'].iloc[idx]\n",
      "        if len(blob_shape) == 1:\n",
      "            blob_box.size = 30, 30\n",
      "        \n",
      "        blobs.append(blob)\n",
      "        boxes.append(blob_box)\n",
      "        shapes.append(blob_shape)\n",
      "        times.append(time)\n",
      "        centroids.append(centroid)\n",
      "    \n",
      "    bounds = sum(boxes)\n",
      "    bounds.grow(40)\n",
      "    min_sq_dim = 150\n",
      "    if bounds.width < min_sq_dim:\n",
      "        bounds.width = min_sq_dim\n",
      "    if bounds.height < min_sq_dim:\n",
      "        bounds.height = min_sq_dim\n",
      "    bounds.square()\n",
      "    \n",
      "    image_fns = experiment.image_files.spanning(times=times)\n",
      "    images = []\n",
      "    for f in image_fns:\n",
      "        im, extents = pil_crop(pillowed(str(f)), bounds)\n",
      "        images.append(adjust_image(im))\n",
      "        \n",
      "    composite = merge_stack(images)\n",
      "    comparr = np.asarray(composite)\n",
      "    \n",
      "    f, ax = plt.subplots()\n",
      "    f.set_size_inches((10, 10))\n",
      "    ax.set_aspect('equal')\n",
      "    ax.imshow(comparr, cmap=plt.cm.YlGn, extent=extents.vflip, interpolation='nearest')\n",
      "    \n",
      "    _, patches = patch_contours(shapes)\n",
      "    \n",
      "    for patch, color in zip(patches, ['blue', 'red']):\n",
      "        patch.set_facecolor(color)\n",
      "        patch.set_alpha(0.6)\n",
      "        ax.add_patch(patch)\n",
      "\n",
      "    x, y = centroids[0]\n",
      "    dx, dy = (c1 - c0 for c0, c1 in zip(*centroids))\n",
      "    ar = 0.1, 0.9\n",
      "    ax.arrow(x + ar[0]*dx, y + ar[0]*dy, (ar[1] - ar[0])*dx, (ar[1] - ar[0])*dy,\n",
      "             width=1.5, head_length=6, head_width=4, length_includes_head=True,\n",
      "             color='yellow', alpha=0.8)\n",
      "    ax.set_title('Gap from id {} to {}, {:0.1f} px, {:0.3f} sec (EID: {})'.format(\n",
      "            lost, found, math.sqrt(dx**2 + dy**2), times[1] - times[0], experiment.id))\n",
      "    #ax.arrow(x, y, dx, dy)\n",
      "        \n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from waldo.tape.viz import show_gap as show_gap2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "show_gap2(experiment, 19213, 19219)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}